{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/afcabre/git-25-09-gh/blob/main/ValoracionEmpresas_USA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9F7J7vT50cxx"
      },
      "source": [
        "# PROYECTO FINAL: Valoraci√≥n de Fundamentales de Empresas Estadounidenses que cotizan en Bolsa y Agente SQL con LangChain\n",
        "\n",
        "**Autor:** Andr√©s Fernando Cabrera - Curso de Fundamentos de LLM y Datos  \n",
        "**Sesi√≥n:** Preprocesamiento de Datos y Agentes SQL\n",
        "\n",
        "---\n",
        "## 1. Introducci√≥n: de Estados Financieros y Precios a Inteligencia de Inversi√≥n Conversacional\n",
        "\n",
        "El escenario propuesto se plantea bajo el contexto de an√°lisis de inversiones, y la resoluci√≥n de las preguntas recurrentes que se suelen enfrentar antes de hacer o liquidar una inversi√≥n, por ejemplo, se quiere saber si el precio que se est√° pagando o recibiendo es considerado justo, es econ√≥mico o costos, frente a sus pares. O se necesita identificar se√±ales de riesgo financiero antes de comprar, y se debe establecer de manera clara, con argumentos provenientes del an√°lisis fundamental, por qu√© una acci√≥n luce atractiva o costosa en un momento espec√≠fico.\n",
        "Tradicionalmente, responder estas preguntas implica construir queries SQL distintas, cruzar estados financieros con precios, calcular m√©tricas derivadas (TTM, m√°rgenes, yields, endeudamiento) y luego consolidar hallazgos en reportes. Este flujo es lento, repetitivo y dif√≠cil de escalar cuando las preguntas se multiplican.\n",
        "\n",
        "Este proyecto final transforma ese proceso manual en un sistema de **an√°lisis conversacional** soportado por un **agente (LLM) conectado a una base de datos SQL**. El pipeline toma datos p√∫blicos de SimFin (estados financieros trimestrales y precios diarios de empresas de USA), los procesa y estructura en un esquema relacional, y habilita un agente capaz de responder preguntas en lenguaje natural. El resultado esperado es una interfaz donde un usuario sin conocimiento de SQL puede explorar, filtrar y explicar oportunidades basadas en fundamentales, con trazabilidad hacia las columnas fuente del dataset.\n",
        "\n",
        "### Objetivos de aprendizaje (enfoque de apropiaci√≥n)\n",
        "\n",
        "Se busca demostrar apropiaci√≥n de lo visto en arquitecturas de agentes con SQL, mediante decisiones de dise√±o y pruebas que conectan datos con preguntas reales de an√°lisis financiero:\n",
        "\n",
        "**Dise√±o de esquema relacional pensando en el agente:**  \n",
        "Se busca dise√±ar tablas y relaciones que faciliten el razonamiento: dimensiones (empresas, industrias), hechos (balance, income, cashflow, precios), y una capa de m√©tricas derivadas con trazabilidad. El objetivo no es solo normalizar, sino habilitar consultas repetibles y comprensibles para un asistente conversacional.\n",
        "\n",
        "**Orquestaci√≥n del agente para preguntas en lenguaje natural:**  \n",
        "EL agente SQL que no solo traduce la preguntas a queries, sino quedebe mantener contexto y usar el lenguaje del dominio. Por ejemplo: ‚Äúbarata vs su industria‚Äù implica comparar percentiles sectoriales; ‚Äúse√±ales de riesgo‚Äù implica revisar deuda, liquidez y cobertura; ‚Äúmejora sostenida‚Äù implica tendencias y estabilidad, no un trimestre aislado. Estas capacidades se prueban con un set de preguntas gu√≠a y casos de prueba.\n",
        "\n",
        "Al finalizar, el objetivo es contar con un prototipo funcional y, sobre todo, con un entendimiento pr√°ctico de c√≥mo **estructurar datos y m√©tricas para maximizar su utilidad en aplicaciones de IA conversacional** apoyadas en SQL.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-MSknLrV0cxz"
      },
      "source": [
        "# 2. Exploraci√≥n inicial de datos\n",
        "\n",
        "## 2.1 Instalaci√≥n de Dependencias\n",
        "Instalar librer√≠as base para ingesti√≥n de CSV, SQL (SQLite) y agente conversacional (LangChain + OpenAI)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install -U pandas numpy pyarrow sqlalchemy tabulate \\\n",
        "  langchain langchain-openai langchain-community openai tiktoken"
      ],
      "metadata": {
        "id": "NXKQXITKIc7v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2 Importaci√≥n de librer√≠as\n",
        "Cargar librer√≠as de trabajo (pandas/numpy para DataFrames, pathlib para rutas, IPython para visualizaci√≥n)."
      ],
      "metadata": {
        "id": "5as3q-b-JRSl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import io\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from IPython.display import display\n",
        "\n",
        "pd.set_option(\"display.max_columns\", None)\n",
        "pd.set_option(\"display.width\", 140)"
      ],
      "metadata": {
        "id": "_Z-zLLYdI1QT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.3 Carga del Dataset Original\n",
        "\n",
        "Cargar los 6 CSV (separador ;) desde /content/data en DataFrames y confirmar dimensiones por archivo y mostrar las primeras filas de cada DataFrame para validar visualmente que la carga fue correcta."
      ],
      "metadata": {
        "id": "4Mp1L93rLbXa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2.3 Carga del Dataset Original\n",
        "DATA_DIR = \"/content/data\"\n",
        "\n",
        "files = {\n",
        "    \"industries\": \"industries.csv\",\n",
        "    \"companies\": \"us-companies.csv\",\n",
        "    \"balance_q\": \"us-balance-quarterly.csv\",\n",
        "    \"income_q\": \"us-income-quarterly.csv\",\n",
        "    \"cashflow_q\": \"us-cashflow-quarterly.csv\",\n",
        "    \"prices_d\": \"us-shareprices-daily.csv\",\n",
        "}\n",
        "\n",
        "dfs = {}\n",
        "\n",
        "print(\"üì¶ Cargando datasets desde:\", DATA_DIR, \"(sep=';')\\n\")\n",
        "\n",
        "for name, fname in files.items():\n",
        "    file_path = str(Path(DATA_DIR) / fname)\n",
        "\n",
        "    try:\n",
        "        df = pd.read_csv(file_path, sep=\";\", low_memory=False)\n",
        "        dfs[name] = df\n",
        "\n",
        "        print(f\"‚úì {fname} cargado correctamente\")\n",
        "        print(f\"  - {name}: {df.shape[0]:,} registros √ó {df.shape[1]} columnas\\n\")\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"‚ùå ERROR: No se encuentra el archivo: {fname}\")\n",
        "        print(f\"   Ruta esperada: {file_path}\")\n",
        "        print(\"   Verifica que el archivo exista en /content/data\")\n",
        "        raise\n",
        "\n",
        "# Vista r√°pida para verificar que los archivos se cargaron bien\n",
        "for name, df in dfs.items():\n",
        "    print(\"\\n\" + \"=\"*90)\n",
        "    print(f\"{name} | shape: {df.shape[0]:,} √ó {df.shape[1]}\")\n",
        "    display(df.head(5))"
      ],
      "metadata": {
        "id": "H_rP_w5mL48f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wg_NVkEz0cx0"
      },
      "source": [
        "### Imports + configuracion base\n",
        "\n",
        "El acceso a los modelos de lenguaje de OpenAI requiere autenticaci√≥n mediante una API key. En entornos de producci√≥n, estas credenciales se gestionan mediante sistemas especializados de gesti√≥n de secretos (como AWS Secrets Manager, Google Cloud Secret Manager, o HashiCorp Vault), pero para desarrollo y educaci√≥n utilizamos `getpass` que solicita la clave de forma interactiva sin almacenarla permanentemente en el c√≥digo fuente del notebook. Esta pr√°ctica es fundamental en seguridad: las API keys expuestas accidentalmente en repositorios p√∫blicos son detectadas autom√°ticamente por bots y pueden generar cargos fraudulentos en cuesti√≥n de minutos.\n",
        "\n",
        "Una vez configurada la variable de entorno `OPENAI_API_KEY`, todas las llamadas posteriores a la API de OpenAI en esta sesi√≥n de Python usar√°n autom√°ticamente esta credencial, sin necesidad de pasarla expl√≠citamente en cada invocaci√≥n. Este patr√≥n mantiene el c√≥digo limpio y centraliza la gesti√≥n de autenticaci√≥n."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8yl9rLDe0cx0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from IPython.display import display\n",
        "\n",
        "pd.set_option(\"display.max_columns\", None)\n",
        "pd.set_option(\"display.width\", 140)\n",
        "\n",
        "DATA_DIR = \"/content/data\"\n",
        "\n",
        "print(\"üìÅ DATA_DIR =\", DATA_DIR)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_bDqwIIf0cx1"
      },
      "source": [
        "## 3. Carga y Exploraci√≥n Inicial del Dataset (EDA)\n",
        "\n",
        "El primer paso cr√≠tico en cualquier pipeline de datos es entender profundamente la materia prima con la que trabajaremos. Esta fase de An√°lisis Exploratorio de Datos (EDA) no es mera curiosidad estad√≠stica, sino una pr√°ctica esencial de ingenier√≠a que informa todas las decisiones posteriores de transformaci√≥n y modelado. Al entender la distribuci√≥n de precios, podemos decidir c√≥mo segmentar el mercado en categor√≠as. Al analizar la cardinalidad de modelos y regiones, podemos estimar el tama√±o de nuestras futuras tablas de lookup. Al inspeccionar el rango temporal de los datos, podemos dise√±ar estrategias apropiadas de an√°lisis de tendencias.\n",
        "\n",
        "Este dataset contiene registros de ventas de veh√≠culos BMW desde 2010 hasta 2024, abarcando m√∫ltiples modelos, regiones geogr√°ficas, configuraciones de veh√≠culos y segmentos de precio. Cada registro representa una transacci√≥n de venta con sus caracter√≠sticas asociadas. La riqueza de este dataset nos permitir√° construir un sistema de inteligencia de negocio que puede responder desde preguntas simples (\"¬øcu√°l es el precio promedio por regi√≥n?\") hasta an√°lisis sofisticados (\"¬øc√≥mo ha evolucionado la adopci√≥n de veh√≠culos el√©ctricos en mercados premium europeos entre 2020-2024?\").\n",
        "\n",
        "**Nota importante:** Aseg√∫rate de subir el archivo `BMW sales data (2010-2024) (1) (1).csv` a la secci√≥n de archivos de Colab (icono de carpeta en el panel izquierdo) antes de ejecutar la siguiente celda."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rLyO7nGM0cx1"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Cargamos el dataset de ventas BMW\n",
        "# Ajusta la ruta si el nombre del archivo es diferente al subirlo\n",
        "file_path = \"BMW sales data (2010-2024) (1) (1).csv\"\n",
        "\n",
        "try:\n",
        "    df = pd.read_csv(file_path)\n",
        "    print(\"‚úì Dataset cargado correctamente\")\n",
        "    print(f\"  Dimensiones: {df.shape[0]:,} registros √ó {df.shape[1]} columnas\")\n",
        "except FileNotFoundError:\n",
        "    print(\"ERROR: No se encuentra el archivo.\")\n",
        "    print(\"Por favor, sube el archivo CSV al entorno de Colab usando el panel de archivos.\")\n",
        "    raise\n",
        "\n",
        "# Inspecci√≥n inicial de la estructura\n",
        "print(\"\\n--- Primeras filas del dataset ---\")\n",
        "display(df.head(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PWGIV8Dg0cx1"
      },
      "outputs": [],
      "source": [
        "# An√°lisis de tipos de datos y valores faltantes\n",
        "print(\"=== INFORMACI√ìN DEL DATASET ===\")\n",
        "df.info()\n",
        "\n",
        "print(\"\\n=== ESTAD√çSTICAS DESCRIPTIVAS NUM√âRICAS ===\")\n",
        "display(df.describe())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WjBtHsRP0cx1"
      },
      "outputs": [],
      "source": [
        "# Exploraci√≥n de variables categ√≥ricas clave\n",
        "print(\"=== AN√ÅLISIS EXPLORATORIO DE VARIABLES CATEG√ìRICAS ===\")\n",
        "\n",
        "print(\"\\n--- Distribuci√≥n de Modelos BMW ---\")\n",
        "model_dist = df['Model'].value_counts()\n",
        "print(model_dist)\n",
        "print(f\"\\nModelos √∫nicos: {df['Model'].nunique()}\")\n",
        "\n",
        "print(\"\\n--- Distribuci√≥n Geogr√°fica de Ventas ---\")\n",
        "region_dist = df['Region'].value_counts()\n",
        "print(region_dist)\n",
        "\n",
        "print(\"\\n--- Distribuci√≥n de Tipos de Combustible ---\")\n",
        "fuel_dist = df['Fuel_Type'].value_counts()\n",
        "print(fuel_dist)\n",
        "print(f\"\\nPorcentaje de veh√≠culos el√©ctricos: {(df['Fuel_Type'] == 'Electric').sum() / len(df) * 100:.2f}%\")\n",
        "\n",
        "print(\"\\n--- Distribuci√≥n de Transmisi√≥n ---\")\n",
        "transmission_dist = df['Transmission'].value_counts()\n",
        "print(transmission_dist)\n",
        "\n",
        "print(\"\\n--- Distribuci√≥n Temporal ---\")\n",
        "year_dist = df['Year'].value_counts().sort_index()\n",
        "print(f\"Rango temporal: {df['Year'].min()} - {df['Year'].max()}\")\n",
        "print(f\"A√±o con m√°s ventas: {year_dist.idxmax()} ({year_dist.max():,} registros)\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "7E7Fxni9GKyx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20bXB_fV0cx2"
      },
      "source": [
        "### Identificaci√≥n de Oportunidades de Feature Engineering\n",
        "\n",
        "A partir de esta exploraci√≥n inicial, podemos identificar varias oportunidades para crear features que amplificar√°n la capacidad del agente SQL para responder preguntas de negocio. Observa que tenemos el a√±o del veh√≠culo pero no la antig√ºedad relativa, tenemos precio absoluto pero no segmentaci√≥n de mercado, tenemos kilometraje y precio por separado pero no eficiencia de valor. Estas son las transformaciones que implementaremos en la siguiente secci√≥n.\n",
        "\n",
        "Tambi√©n notamos que los modelos BMW tienen jerarqu√≠as impl√≠citas: las series num√©ricas (3, 5, 7) representan segmentos de sed√°n progresivamente m√°s premium, los modelos X representan SUVs, los modelos M son versiones de alto rendimiento, y los modelos i son la l√≠nea de veh√≠culos el√©ctricos e h√≠bridos. Hacer estas jerarqu√≠as expl√≠citas en nuestro esquema de base de datos facilitar√° queries como \"analiza la evoluci√≥n de ventas en el segmento SUV\" o \"compara el rendimiento de modelos de alto rendimiento versus modelos est√°ndar\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6UuhFR1n0cx2"
      },
      "source": [
        "## 4. Pipeline de Preprocesamiento y Feature Engineering\n",
        "\n",
        "Esta es la fase donde aplicamos transformaciones inteligentes que convierten datos crudos en informaci√≥n estructurada para an√°lisis. El objetivo no es solo limpiar datos (este dataset ya est√° razonablemente limpio), sino enriquecer la representaci√≥n con features derivadas que hacen expl√≠cito conocimiento impl√≠cito del dominio. Cada feature que creamos es una decisi√≥n de dise√±o que balancea complejidad de implementaci√≥n versus utilidad anal√≠tica.\n",
        "\n",
        "Construiremos nuestro pipeline como una serie de funciones modulares y componibles, donde cada funci√≥n tiene una responsabilidad clara y puede testearse independientemente. Este enfoque no solo es buena pr√°ctica de ingenier√≠a de software, sino que facilita enormemente el debugging cuando el agente SQL genera queries incorrectas debido a problemas en los datos subyacentes.\n",
        "\n",
        "### Fase 1: C√°lculo de Antig√ºedad del Veh√≠culo\n",
        "\n",
        "El a√±o de manufactura es un dato factual, pero lo que realmente importa para an√°lisis de pricing, demanda y depreciaci√≥n es la antig√ºedad relativa del veh√≠culo. Un auto de 2015 en el a√±o 2024 tiene 9 a√±os de antig√ºedad, lo cual afecta dram√°ticamente su valor de mercado. Esta feature tambi√©n facilita queries temporales como \"analiza veh√≠culos con menos de 3 a√±os de antig√ºedad\" que de otro modo requerir√≠an aritm√©tica compleja en SQL con la fecha actual."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aa_5wukM0cx2"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "def calculate_vehicle_age(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Calcula la antig√ºedad del veh√≠culo basado en el a√±o actual.\n",
        "\n",
        "    Args:\n",
        "        df: DataFrame con columna 'Year'\n",
        "\n",
        "    Returns:\n",
        "        DataFrame con nueva columna 'Vehicle_Age'\n",
        "    \"\"\"\n",
        "    df_processed = df.copy()\n",
        "    current_year = datetime.now().year\n",
        "\n",
        "    # Calculamos antig√ºedad\n",
        "    df_processed['Vehicle_Age'] = current_year - df_processed['Year']\n",
        "\n",
        "    # Aseguramos que no haya valores negativos (errores de datos futuros)\n",
        "    df_processed['Vehicle_Age'] = df_processed['Vehicle_Age'].clip(lower=0)\n",
        "\n",
        "    return df_processed\n",
        "\n",
        "# Aplicamos la transformaci√≥n\n",
        "df_processed = calculate_vehicle_age(df)\n",
        "\n",
        "print(\"‚úì Feature 'Vehicle_Age' calculada\")\n",
        "print(\"\\n--- Distribuci√≥n de Antig√ºedad de Veh√≠culos ---\")\n",
        "print(df_processed['Vehicle_Age'].describe())\n",
        "print(f\"\\nRango: {df_processed['Vehicle_Age'].min()} - {df_processed['Vehicle_Age'].max()} a√±os\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7EKfNFCn0cx2"
      },
      "source": [
        "### Fase 2: Segmentaci√≥n de Mercado por Precio\n",
        "\n",
        "Los precios absolutos en USD son √∫tiles para comparaciones num√©ricas, pero para an√°lisis estrat√©gico de mercado necesitamos categor√≠as que representen segmentos de consumidores. Un veh√≠culo de $30,000 USD compite en un segmento fundamentalmente diferente al de uno de $150,000 USD. Crearemos cuatro categor√≠as de segmentaci√≥n: Budget (econ√≥mico), Mid-range (rango medio), Premium (premium) y Luxury (lujo). Estos umbrales se basan en conocimiento de la industria automotriz sobre c√≥mo BMW posiciona sus modelos.\n",
        "\n",
        "Esta categorizaci√≥n permite queries sem√°nticas como \"analiza la adopci√≥n de veh√≠culos el√©ctricos en el segmento premium\" que ser√≠an extremadamente verbosas si tuvi√©ramos que especificar rangos de precio en cada query."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3nUHff1j0cx2"
      },
      "outputs": [],
      "source": [
        "def create_price_segments(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Crea categor√≠as de segmentaci√≥n de mercado basadas en precio.\n",
        "\n",
        "    Args:\n",
        "        df: DataFrame con columna 'Price_USD'\n",
        "\n",
        "    Returns:\n",
        "        DataFrame con nueva columna 'Price_Segment'\n",
        "    \"\"\"\n",
        "    df_processed = df.copy()\n",
        "\n",
        "    # Definimos umbrales basados en la estructura de mercado BMW\n",
        "    def categorize_price(price):\n",
        "        if price < 50000:\n",
        "            return 'Budget'\n",
        "        elif price < 80000:\n",
        "            return 'Mid-range'\n",
        "        elif price < 110000:\n",
        "            return 'Premium'\n",
        "        else:\n",
        "            return 'Luxury'\n",
        "\n",
        "    df_processed['Price_Segment'] = df_processed['Price_USD'].apply(categorize_price)\n",
        "\n",
        "    return df_processed\n",
        "\n",
        "# Aplicamos segmentaci√≥n\n",
        "df_processed = create_price_segments(df_processed)\n",
        "\n",
        "print(\"‚úì Feature 'Price_Segment' creada\")\n",
        "print(\"\\n--- Distribuci√≥n de Segmentos de Precio ---\")\n",
        "segment_dist = df_processed['Price_Segment'].value_counts()\n",
        "print(segment_dist)\n",
        "print(\"\\n--- Precio Promedio por Segmento ---\")\n",
        "avg_by_segment = df_processed.groupby('Price_Segment')['Price_USD'].mean().sort_values()\n",
        "print(avg_by_segment)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3BYr-Z6w0cx3"
      },
      "source": [
        "### Fase 3: M√©tricas de Eficiencia y Valor Relativo\n",
        "\n",
        "El precio absoluto y el kilometraje son datos importantes individualmente, pero su ratio captura una dimensi√≥n cr√≠tica de valor: ¬øcu√°nto cuesta este veh√≠culo por cada kil√≥metro ya recorrido? Esta m√©trica es fundamental para an√°lisis de valor relativo en el mercado de autos usados. Un veh√≠culo de $100,000 con 10,000 km tiene un precio por kil√≥metro muy diferente al de uno de $50,000 con 150,000 km.\n",
        "\n",
        "Tambi√©n calcularemos una estimaci√≥n simplificada de depreciaci√≥n anual. En el mercado automotriz, los veh√≠culos t√≠picamente deprecian m√°s agresivamente en los primeros a√±os. Crearemos una m√©trica que capture esta tendencia de forma aproximada, √∫til para an√°lisis comparativo aunque no pretende ser un modelo preciso de valuaci√≥n."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k8L4LdY20cx3"
      },
      "outputs": [],
      "source": [
        "def calculate_value_metrics(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Calcula m√©tricas derivadas de valor y eficiencia.\n",
        "\n",
        "    Args:\n",
        "        df: DataFrame con columnas 'Price_USD', 'Mileage_KM', 'Vehicle_Age'\n",
        "\n",
        "    Returns:\n",
        "        DataFrame con nuevas columnas de m√©tricas\n",
        "    \"\"\"\n",
        "    df_processed = df.copy()\n",
        "\n",
        "    # M√©trica 1: Precio por Kil√≥metro (evitando divisi√≥n por cero)\n",
        "    df_processed['Price_per_KM'] = np.where(\n",
        "        df_processed['Mileage_KM'] > 0,\n",
        "        df_processed['Price_USD'] / df_processed['Mileage_KM'],\n",
        "        df_processed['Price_USD']  # Si kilometraje es 0, usamos precio directamente\n",
        "    )\n",
        "    df_processed['Price_per_KM'] = df_processed['Price_per_KM'].round(2)\n",
        "\n",
        "    # M√©trica 2: Depreciaci√≥n Anual Estimada\n",
        "    # Asumimos un precio de lista promedio y calculamos depreciaci√≥n\n",
        "    # F√≥rmula simplificada: (Precio Estimado Nuevo - Precio Actual) / A√±os\n",
        "    estimated_new_price = df_processed.groupby('Model')['Price_USD'].transform('max')\n",
        "    df_processed['Annual_Depreciation'] = np.where(\n",
        "        df_processed['Vehicle_Age'] > 0,\n",
        "        (estimated_new_price - df_processed['Price_USD']) / df_processed['Vehicle_Age'],\n",
        "        0\n",
        "    )\n",
        "    df_processed['Annual_Depreciation'] = df_processed['Annual_Depreciation'].clip(lower=0).round(2)\n",
        "\n",
        "    # M√©trica 3: Kilometraje Anual Promedio\n",
        "    df_processed['Annual_Mileage'] = np.where(\n",
        "        df_processed['Vehicle_Age'] > 0,\n",
        "        df_processed['Mileage_KM'] / df_processed['Vehicle_Age'],\n",
        "        df_processed['Mileage_KM']\n",
        "    )\n",
        "    df_processed['Annual_Mileage'] = df_processed['Annual_Mileage'].round(0).astype(int)\n",
        "\n",
        "    return df_processed\n",
        "\n",
        "# Aplicamos c√°lculo de m√©tricas\n",
        "df_processed = calculate_value_metrics(df_processed)\n",
        "\n",
        "print(\"‚úì M√©tricas de valor calculadas: Price_per_KM, Annual_Depreciation, Annual_Mileage\")\n",
        "print(\"\\n--- Estad√≠sticas de Nuevas M√©tricas ---\")\n",
        "display(df_processed[['Price_per_KM', 'Annual_Depreciation', 'Annual_Mileage']].describe())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KuCh2Q7L0cx3"
      },
      "source": [
        "### Fase 4: Jerarqu√≠a de Modelos y L√≠neas de Producto\n",
        "\n",
        "Los modelos BMW tienen una estructura jer√°rquica impl√≠cita que es fundamental para an√°lisis estrat√©gico. Las series num√©ricas (3, 5, 7) representan sedanes de lujo progresivamente m√°s premium, con la Serie 3 siendo el modelo de entrada y la Serie 7 el flagship. Los modelos X (X1, X3, X5, X7) son SUVs con numeraci√≥n similar indicando tama√±o y posicionamiento. Los modelos M son versiones de alto rendimiento de los modelos est√°ndar. Los modelos i (i3, i8, iX) representan la l√≠nea de veh√≠culos el√©ctricos e h√≠bridos de BMW.\n",
        "\n",
        "Hacer estas jerarqu√≠as expl√≠citas mediante una columna `Product_Line` permitir√° al agente responder preguntas como \"compara el rendimiento de ventas entre sedanes y SUVs\" o \"analiza la adopci√≥n de la l√≠nea el√©ctrica i versus modelos tradicionales\". Sin esta categorizaci√≥n, el agente tendr√≠a que hacer pattern matching complejo sobre nombres de modelos, lo cual es propenso a errores."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eDvekLTP0cx3"
      },
      "outputs": [],
      "source": [
        "def categorize_product_line(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Categoriza modelos en l√≠neas de producto basadas en nomenclatura BMW.\n",
        "\n",
        "    Args:\n",
        "        df: DataFrame con columna 'Model'\n",
        "\n",
        "    Returns:\n",
        "        DataFrame con nueva columna 'Product_Line'\n",
        "    \"\"\"\n",
        "    df_processed = df.copy()\n",
        "\n",
        "    def classify_model(model):\n",
        "        model = str(model)\n",
        "        if model.startswith('X'):\n",
        "            return 'SUV'\n",
        "        elif model.startswith('M'):\n",
        "            return 'Performance'\n",
        "        elif model.startswith('i') or model.startswith('I'):\n",
        "            return 'Electric/Hybrid'\n",
        "        elif 'Series' in model:\n",
        "            return 'Sedan'\n",
        "        else:\n",
        "            return 'Other'\n",
        "\n",
        "    df_processed['Product_Line'] = df_processed['Model'].apply(classify_model)\n",
        "\n",
        "    return df_processed\n",
        "\n",
        "# Aplicamos categorizaci√≥n\n",
        "df_processed = categorize_product_line(df_processed)\n",
        "\n",
        "print(\"‚úì Feature 'Product_Line' creada\")\n",
        "print(\"\\n--- Distribuci√≥n de L√≠neas de Producto ---\")\n",
        "product_line_dist = df_processed['Product_Line'].value_counts()\n",
        "print(product_line_dist)\n",
        "\n",
        "print(\"\\n--- Precio Promedio por L√≠nea de Producto ---\")\n",
        "avg_price_by_line = df_processed.groupby('Product_Line')['Price_USD'].mean().sort_values(ascending=False)\n",
        "print(avg_price_by_line)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4P5XTRQM0cx3"
      },
      "source": [
        "### Fase 5: Normalizaci√≥n de Nombres de Columnas para SQL\n",
        "\n",
        "Las convenciones de nomenclatura de columnas en el dataset original usan PascalCase con guiones bajos (por ejemplo, `Fuel_Type`, `Engine_Size_L`). Aunque t√©cnicamente SQL puede manejar estos nombres, la convenci√≥n est√°ndar en bases de datos es usar lowercase con guiones bajos (snake_case). Esta normalizaci√≥n previene problemas de case sensitivity entre diferentes sistemas de bases de datos y hace que las queries generadas por el agente sean m√°s idiom√°ticas y f√°ciles de leer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qYZDqDNe0cx3"
      },
      "outputs": [],
      "source": [
        "def normalize_column_names(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Normaliza nombres de columnas a snake_case lowercase (convenci√≥n SQL).\n",
        "\n",
        "    Args:\n",
        "        df: DataFrame con nombres de columnas a normalizar\n",
        "\n",
        "    Returns:\n",
        "        DataFrame con nombres de columnas normalizados\n",
        "    \"\"\"\n",
        "    df_processed = df.copy()\n",
        "\n",
        "    # Convertimos a lowercase y reemplazamos espacios\n",
        "    df_processed.columns = [col.lower().replace(' ', '_') for col in df_processed.columns]\n",
        "\n",
        "    return df_processed\n",
        "\n",
        "# Aplicamos normalizaci√≥n\n",
        "df_final = normalize_column_names(df_processed)\n",
        "\n",
        "print(\"‚úì Nombres de columnas normalizados a snake_case\")\n",
        "print(\"\\n--- Columnas Finales del Dataset ---\")\n",
        "print(df_final.columns.tolist())\n",
        "\n",
        "print(\"\\n--- Vista Final del Dataset Procesado ---\")\n",
        "display(df_final.head(10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dzhyWW_a0cx3"
      },
      "source": [
        "### Resumen del Pipeline de Preprocesamiento\n",
        "\n",
        "En esta fase hemos transformado nuestro dataset crudo en una representaci√≥n enriquecida que maximiza la utilidad para an√°lisis de negocio. Creamos cinco nuevas features que amplifican la capacidad del agente SQL para razonar sobre los datos: antig√ºedad de veh√≠culo (facilita an√°lisis temporal), segmentaci√≥n de precio (permite an√°lisis de mercado), m√©tricas de valor (habilitan comparaciones de eficiencia), l√≠nea de producto (estructura jerarqu√≠a de modelos) y normalizaci√≥n de nombres (mejora idiomaticidad de SQL).\n",
        "\n",
        "Cada una de estas transformaciones fue una decisi√≥n de dise√±o informada por comprensi√≥n del dominio automotriz. No simplemente aplicamos transformaciones est√°ndar, sino que pensamos profundamente sobre qu√© preguntas de negocio son importantes y c√≥mo estructurar los datos para facilitarlas. Esta es la esencia del feature engineering efectivo: traducir conocimiento de dominio en representaciones de datos que amplifican el razonamiento de m√°quinas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vLoRo7Uy0cx3"
      },
      "source": [
        "## 5. Dise√±o del Esquema Relacional: Normalizaci√≥n Estrat√©gica\n",
        "\n",
        "Ahora enfrentamos decisiones arquitect√≥nicas fundamentales sobre c√≥mo estructurar nuestros datos en una base de datos relacional. Para un dataset de este tipo, tenemos dos opciones principales: mantener todo en una tabla desnormalizada (flat) que es simple pero redundante, o normalizar en m√∫ltiples tablas relacionadas que es m√°s complejo pero m√°s eficiente y expresivo.\n",
        "\n",
        "Tomaremos un enfoque h√≠brido pragm√°tico: crearemos una tabla principal de transacciones (`sales_transactions`) que contendr√° la mayor√≠a de los datos, junto con tablas de lookup para entidades que tienen alta cardinalidad y metadata asociada. Este dise√±o balancea simplicidad (menos JOINs necesarios para queries comunes) con eficiencia (no repetir strings largos millones de veces).\n",
        "\n",
        "Nuestro esquema consistir√° en:\n",
        "\n",
        "**Tabla `sales_transactions`:** La tabla central que contiene cada transacci√≥n de venta con todas las features calculadas. Esta ser√° el punto de entrada natural para la mayor√≠a de las queries del agente.\n",
        "\n",
        "**Tabla `models`:** Cat√°logo de modelos BMW con metadata adicional como l√≠nea de producto y segmento t√≠pico. Esta separaci√≥n permite agregar informaci√≥n futura (como a√±o de lanzamiento del modelo, si est√° discontinuado, etc.) sin tocar las transacciones.\n",
        "\n",
        "**Tabla `regions`:** Aunque solo tenemos el nombre de la regi√≥n en el dataset original, crearemos esta tabla para facilitar futuras extensiones (como agrupar regiones en continentes o zonas econ√≥micas).\n",
        "\n",
        "**Vista `sales_summary`:** Una vista materializada que pre-calcula estad√≠sticas agregadas frecuentemente consultadas. Las vistas son como \"queries guardadas\" que simplifican dram√°ticamente la generaci√≥n de SQL por parte del agente.\n",
        "\n",
        "Una nota importante sobre este dise√±o: en un sistema de producci√≥n real con millones de registros y m√∫ltiples fuentes de datos, normalizar√≠amos m√°s agresivamente y tendr√≠amos esquemas de dimensiones (star schema o snowflake schema). Para este ejercicio educativo, priorizamos claridad y facilidad de uso para el agente sobre optimizaci√≥n extrema."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4s8Fyu7D0cx3"
      },
      "outputs": [],
      "source": [
        "from sqlalchemy import create_engine, text\n",
        "\n",
        "# Creamos el motor de base de datos SQLite\n",
        "db_path = \"bmw_sales_intelligence.db\"\n",
        "engine = create_engine(f\"sqlite:///{db_path}\")\n",
        "\n",
        "print(f\"‚úì Motor de base de datos creado: {db_path}\")\n",
        "\n",
        "# Tabla principal: sales_transactions\n",
        "# Esta contiene todas las transacciones con sus features calculadas\n",
        "df_final.to_sql('sales_transactions', engine, if_exists='replace', index=False)\n",
        "print(\"  ‚úì Tabla 'sales_transactions' creada\")\n",
        "print(f\"    Registros: {len(df_final):,}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YpYr7UhD0cx3"
      },
      "source": [
        "### Creaci√≥n de Tablas de Lookup y Cat√°logos\n",
        "\n",
        "Ahora crearemos tablas auxiliares que proporcionan metadata estructurada sobre entidades clave. Estas tablas son relativamente peque√±as pero mejoran significativamente la expresividad de queries al permitir JOINs informativos y proporcionar puntos de extensi√≥n para metadata futura."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x6JyoxYe0cx4"
      },
      "outputs": [],
      "source": [
        "# Tabla de cat√°logo de modelos\n",
        "models_catalog = df_final[['model', 'product_line']].drop_duplicates()\n",
        "models_catalog = models_catalog.reset_index(drop=True)\n",
        "models_catalog.insert(0, 'model_id', range(1, len(models_catalog) + 1))\n",
        "\n",
        "models_catalog.to_sql('models', engine, if_exists='replace', index=False)\n",
        "print(\"  ‚úì Tabla 'models' creada\")\n",
        "print(f\"    Modelos √∫nicos: {len(models_catalog)}\")\n",
        "\n",
        "# Tabla de regiones\n",
        "regions_catalog = pd.DataFrame({\n",
        "    'region_id': range(1, df_final['region'].nunique() + 1),\n",
        "    'region_name': sorted(df_final['region'].unique())\n",
        "})\n",
        "\n",
        "regions_catalog.to_sql('regions', engine, if_exists='replace', index=False)\n",
        "print(\"  ‚úì Tabla 'regions' creada\")\n",
        "print(f\"    Regiones √∫nicas: {len(regions_catalog)}\")\n",
        "\n",
        "print(\"\\n--- Cat√°logo de Modelos ---\")\n",
        "display(models_catalog)\n",
        "\n",
        "print(\"\\n--- Cat√°logo de Regiones ---\")\n",
        "display(regions_catalog)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_vYP75I90cx4"
      },
      "source": [
        "### Creaci√≥n de Vista Agregada para An√°lisis R√°pido\n",
        "\n",
        "Las vistas SQL son una herramienta poderosa para simplificar el trabajo del agente. Una vista es esencialmente una query guardada que puede ser consultada como si fuera una tabla. Crearemos una vista `sales_summary` que pre-calcula estad√≠sticas agregadas comunes. Esto tiene dos beneficios: primero, queries que necesitan estas agregaciones se vuelven mucho m√°s simples (el agente puede simplemente SELECT FROM la vista); segundo, para el LLM es m√°s f√°cil razonar sobre una vista con nombre sem√°ntico que construir agregaciones complejas desde cero.\n",
        "\n",
        "Nuestra vista agregar√° datos por modelo, regi√≥n y a√±o, calculando m√©tricas como volumen total de ventas, precio promedio, kilometraje promedio y distribuci√≥n de tipos de combustible. Estas son precisamente las dimensiones sobre las que stakeholders de negocio t√≠picamente quieren analizar rendimiento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EvA16FB-0cx4"
      },
      "outputs": [],
      "source": [
        "# Definimos la vista SQL de resumen de ventas\n",
        "create_view_sql = \"\"\"\n",
        "CREATE VIEW IF NOT EXISTS sales_summary AS\n",
        "SELECT\n",
        "    model,\n",
        "    product_line,\n",
        "    region,\n",
        "    year,\n",
        "    price_segment,\n",
        "    fuel_type,\n",
        "    COUNT(*) as transaction_count,\n",
        "    SUM(sales_volume) as total_volume,\n",
        "    AVG(price_usd) as avg_price,\n",
        "    AVG(mileage_km) as avg_mileage,\n",
        "    AVG(vehicle_age) as avg_vehicle_age,\n",
        "    AVG(price_per_km) as avg_price_per_km,\n",
        "    AVG(annual_depreciation) as avg_annual_depreciation,\n",
        "    AVG(engine_size_l) as avg_engine_size\n",
        "FROM sales_transactions\n",
        "GROUP BY model, product_line, region, year, price_segment, fuel_type\n",
        ";\n",
        "\"\"\"\n",
        "\n",
        "# Ejecutamos la creaci√≥n de la vista\n",
        "with engine.connect() as conn:\n",
        "    conn.execute(text(create_view_sql))\n",
        "    conn.commit()\n",
        "\n",
        "print(\"‚úì Vista 'sales_summary' creada exitosamente\")\n",
        "\n",
        "# Verificamos la vista consult√°ndola\n",
        "test_query = \"\"\"\n",
        "SELECT model, region, year, total_volume, avg_price\n",
        "FROM sales_summary\n",
        "WHERE year >= 2020\n",
        "ORDER BY total_volume DESC\n",
        "LIMIT 10\n",
        "\"\"\"\n",
        "df_view_test = pd.read_sql_query(test_query, engine)\n",
        "print(\"\\n--- Top 10 Combinaciones Modelo-Regi√≥n por Volumen (2020+) ---\")\n",
        "display(df_view_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ns_qSkcB0cx4"
      },
      "source": [
        "### Verificaci√≥n de Integridad del Esquema\n",
        "\n",
        "Antes de entregar nuestra base de datos al agente SQL, ejecutamos una serie de tests de integridad para confirmar que el esquema funciona correctamente y que no hay inconsistencias en los datos. Esta verificaci√≥n proactiva previene que el agente genere queries sobre estructuras defectuosas que producir√≠an resultados incorrectos o errores cr√≠pticos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f5s_bRhR0cx4"
      },
      "outputs": [],
      "source": [
        "print(\"=== VERIFICACI√ìN DE INTEGRIDAD DEL ESQUEMA ===\")\n",
        "\n",
        "# Test 1: Conteo de registros en cada tabla\n",
        "with engine.connect() as conn:\n",
        "    tables = ['sales_transactions', 'models', 'regions']\n",
        "    for table in tables:\n",
        "        result = conn.execute(text(f\"SELECT COUNT(*) as count FROM {table}\")).fetchone()\n",
        "        print(f\"  Tabla '{table}': {result[0]:,} registros\")\n",
        "\n",
        "# Test 2: Verificar que todos los modelos en transactions existen en cat√°logo\n",
        "query_model_check = \"\"\"\n",
        "SELECT COUNT(DISTINCT st.model) as models_in_transactions,\n",
        "       (SELECT COUNT(*) FROM models) as models_in_catalog\n",
        "FROM sales_transactions st\n",
        "\"\"\"\n",
        "result = pd.read_sql_query(query_model_check, engine)\n",
        "print(f\"\\n  Modelos en transacciones: {result['models_in_transactions'].values[0]}\")\n",
        "print(f\"  Modelos en cat√°logo: {result['models_in_catalog'].values[0]}\")\n",
        "\n",
        "# Test 3: Verificar distribuci√≥n de price_segment\n",
        "query_segment_dist = \"\"\"\n",
        "SELECT price_segment, COUNT(*) as count\n",
        "FROM sales_transactions\n",
        "GROUP BY price_segment\n",
        "ORDER BY\n",
        "    CASE price_segment\n",
        "        WHEN 'Budget' THEN 1\n",
        "        WHEN 'Mid-range' THEN 2\n",
        "        WHEN 'Premium' THEN 3\n",
        "        WHEN 'Luxury' THEN 4\n",
        "    END\n",
        "\"\"\"\n",
        "segment_dist = pd.read_sql_query(query_segment_dist, engine)\n",
        "print(\"\\n--- Distribuci√≥n de Segmentos de Precio ---\")\n",
        "display(segment_dist)\n",
        "\n",
        "# Test 4: Verificar integridad de vista sales_summary\n",
        "query_view_check = \"SELECT COUNT(*) as rows FROM sales_summary\"\n",
        "view_rows = pd.read_sql_query(query_view_check, engine)\n",
        "print(f\"\\n  Filas en vista sales_summary: {view_rows['rows'].values[0]:,}\")\n",
        "\n",
        "print(\"\\n‚úì Verificaciones de integridad completadas. La base de datos est√° lista para consultas.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hpm8vp6V0cx4"
      },
      "source": [
        "## 6. Configuraci√≥n del Agente SQL con LangChain\n",
        "\n",
        "Llegamos al momento culminante: conectar nuestra base de datos cuidadosamente dise√±ada con un agente de lenguaje natural que puede razonar sobre ella. El agente SQL de LangChain es una pieza sofisticada de ingenier√≠a que combina varias capacidades cr√≠ticas. Primero, inspecciona autom√°ticamente el esquema de la base de datos para entender qu√© tablas, columnas y relaciones est√°n disponibles. Segundo, usa el modelo de lenguaje para interpretar preguntas en lenguaje natural y razonar sobre qu√© informaci√≥n necesita. Tercero, genera queries SQL sint√°cticamente correctas y sem√°nticamente apropiadas. Cuarto, ejecuta esas queries y obtiene resultados. Finalmente, interpreta los resultados y formula respuestas en lenguaje natural que son comprensibles para usuarios no t√©cnicos.\n",
        "\n",
        "Este pipeline completo es invisible para el usuario final, quien simplemente hace preguntas como si estuviera hablando con un analista de datos humano experto. La magia est√° en que el agente no est√° pre-programado con queries espec√≠ficas, sino que genera din√°micamente el SQL apropiado para cada pregunta √∫nica. Esta flexibilidad es lo que diferencia un sistema de reportes tradicional (respuestas predefinidas a preguntas predefinidas) de un asistente de inteligencia de negocio verdaderamente conversacional.\n",
        "\n",
        "La configuraci√≥n del agente requiere dos componentes principales: el objeto `SQLDatabase` de LangChain que act√∫a como interfaz con nuestra base SQLite, y el `ChatOpenAI` que proporciona las capacidades de razonamiento del modelo de lenguaje. Un par√°metro cr√≠tico es `temperature=0`, que configura el modelo para que sea completamente determinista. Para generaci√≥n de c√≥digo SQL, no queremos creatividad o variaci√≥n aleatoria; queremos precisi√≥n y consistencia. Cada vez que se hace la misma pregunta, deber√≠amos obtener la misma query SQL."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "# Forzar codificaci√≥n UTF-8 en todo el entorno\n",
        "os.environ['PYTHONIOENCODING'] = 'utf-8'\n",
        "os.environ['LANG'] = 'C.UTF-8'\n",
        "\n",
        "# Para Colab espec√≠ficamente\n",
        "if 'google.colab' in sys.modules:\n",
        "    import locale\n",
        "    locale.getpreferredencoding = lambda: \"UTF-8\""
      ],
      "metadata": {
        "id": "HscKRn-_2lbA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.utilities import SQLDatabase\n",
        "from langchain_community.agent_toolkits import create_sql_agent\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "# Conectamos LangChain a nuestra base de datos\n",
        "db = SQLDatabase.from_uri(f\"sqlite:///{db_path}\")\n",
        "\n",
        "print(\"Base de datos conectada. Tablas disponibles:\")\n",
        "print(db.get_usable_table_names())\n",
        "\n",
        "print(\"\\n--- Schema de la tabla principal ---\")\n",
        "print(db.get_table_info(['sales_transactions']))\n",
        "\n",
        "# Recreamos el LLM con la API key correcta\n",
        "llm = ChatOpenAI(\n",
        "    model=\"gpt-5.1\",\n",
        "\n",
        ")\n",
        "\n",
        "# Recreamos el agente\n",
        "agent_executor = create_sql_agent(\n",
        "    llm,\n",
        "    db=db,\n",
        "    agent_type=\"openai-tools\",\n",
        "    verbose=True,\n",
        "    handle_parsing_errors=True\n",
        ")\n",
        "\n",
        "print(\"‚úì Agente SQL configurado exitosamente\")"
      ],
      "metadata": {
        "id": "-phgzRhk4G7X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZDS2pmp0cx4"
      },
      "source": [
        "## 7. Demostraci√≥n: Preguntas de Negocio en Lenguaje Natural\n",
        "\n",
        "Es hora de poner a prueba nuestro sistema con una serie de preguntas de negocio de complejidad creciente. Estas preguntas est√°n dise√±adas para demostrar diferentes capacidades del agente y, crucialmente, para evidenciar c√≥mo el dise√±o de nuestra base de datos facilita o dificulta ciertos tipos de an√°lisis.\n",
        "\n",
        "Observa cuidadosamente el output verbose de cada query. Ver√°s el proceso de razonamiento completo del agente: c√≥mo examina el esquema, formula una estrategia, genera SQL (que a veces necesita iterar si hay errores de sintaxis o l√≥gica), ejecuta la query, obtiene resultados y finalmente formula una respuesta en lenguaje natural. Esta transparencia es invaluable para debugging y para entender c√≥mo decisiones de dise√±o del esquema impactan la eficiencia del agente.\n",
        "\n",
        "### Pregunta 1: An√°lisis B√°sico de Agregaci√≥n por Regi√≥n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UA4FLFOC0cx4"
      },
      "outputs": [],
      "source": [
        "query1 = \"Cual es el volumen total de ventas por region\"  # Sin tildes\n",
        "\n",
        "print(f\"PREGUNTA: {query1}\\n\")\n",
        "print(\"=\"*80)\n",
        "response1 = agent_executor.invoke({\"input\": query1})\n",
        "print(\"=\"*80)\n",
        "print(f\"\\nüìä RESPUESTA FINAL:\\n{response1['output']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iHCJ4Dde0cx4"
      },
      "source": [
        "### Pregunta 2: Uso de Features Calculadas - Segmentaci√≥n de Mercado\n",
        "\n",
        "Esta pregunta demuestra el valor del feature engineering. Sin la columna `price_segment` que creamos, el agente tendr√≠a que generar CASE statements complejos con rangos num√©ricos. Con la feature pre-calculada, la query es simple y sem√°nticamente clara."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kd0KxPWO0cx5"
      },
      "outputs": [],
      "source": [
        "query2 = \"¬øCu√°l es la distribuci√≥n de ventas por segmento de precio (Budget, Mid-range, Premium, Luxury)?\"\n",
        "\n",
        "print(f\"PREGUNTA: {query2}\\n\")\n",
        "print(\"=\"*80)\n",
        "response2 = agent_executor.invoke({\"input\": query2})\n",
        "print(\"=\"*80)\n",
        "print(f\"\\nüìä RESPUESTA FINAL:\\n{response2['output']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31sYNqGE0cx5"
      },
      "source": [
        "### Pregunta 3: An√°lisis de Tendencias Temporales\n",
        "\n",
        "Esta pregunta requiere agrupaci√≥n temporal y c√°lculo de m√©tricas agregadas. Demuestra c√≥mo el agente puede razonar sobre evoluci√≥n de mercado a lo largo del tiempo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4SrTCsZh0cx5"
      },
      "outputs": [],
      "source": [
        "query3 = \"¬øC√≥mo ha evolucionado el precio promedio de  los modelos de veh√≠culos la base de datos (todos son de la marca BMW) desglosalo por modelo entre 2020 y 2024?\"\n",
        "\n",
        "print(f\"PREGUNTA: {query3}\\n\")\n",
        "print(\"=\"*80)\n",
        "response3 = agent_executor.invoke({\"input\": query3})\n",
        "print(\"=\"*80)\n",
        "print(f\"\\nüìä RESPUESTA FINAL:\\n{response3['output']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LT7Y0R1N0cx5"
      },
      "source": [
        "### Pregunta 4: Uso de Jerarqu√≠a de L√≠neas de Producto\n",
        "\n",
        "Esta pregunta aprovecha la columna `product_line` que categoriz√≥ modelos en SUV, Sedan, Performance, etc. Sin esta categorizaci√≥n, el agente tendr√≠a dificultades para entender qu√© constituye un \"SUV\" versus otros tipos de veh√≠culos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aD_yxElM0cx5"
      },
      "outputs": [],
      "source": [
        "query4 = \"Compara el volumen de ventas entre SUVs y sedanes. ¬øQu√© l√≠nea de producto tiene mejor rendimiento?\"\n",
        "\n",
        "print(f\"PREGUNTA: {query4}\\n\")\n",
        "print(\"=\"*80)\n",
        "response4 = agent_executor.invoke({\"input\": query4})\n",
        "print(\"=\"*80)\n",
        "print(f\"\\nüìä RESPUESTA FINAL:\\n{response4['output']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KU1d6Cau0cx5"
      },
      "source": [
        "### Pregunta 5: An√°lisis de Adopci√≥n de Tecnolog√≠as Limpias\n",
        "\n",
        "Esta pregunta sobre veh√≠culos el√©ctricos y tipos de combustible es relevante para estrategia de sostenibilidad corporativa. Demuestra c√≥mo el agente puede filtrar por caracter√≠sticas espec√≠ficas y calcular proporciones."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AmFemHXQ0cx5"
      },
      "outputs": [],
      "source": [
        "query5 = \"¬øCu√°l es el porcentaje de veh√≠culos el√©ctricos en el total de ventas? ¬øY c√≥mo se distribuyen los tipos de combustible?\"\n",
        "\n",
        "print(f\"PREGUNTA: {query5}\\n\")\n",
        "print(\"=\"*80)\n",
        "response5 = agent_executor.invoke({\"input\": query5})\n",
        "print(\"=\"*80)\n",
        "print(f\"\\nüìä RESPUESTA FINAL:\\n{response5['output']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "URN6TAYS0cx6"
      },
      "source": [
        "### Pregunta 6: An√°lisis Complejo Multi-Dimensional\n",
        "\n",
        "Esta pregunta requiere filtrado por m√∫ltiples dimensiones (regi√≥n, tipo de combustible, segmento de precio) y c√°lculo de m√©tricas agregadas. Es el tipo de an√°lisis que tradicionalmente requerir√≠a m√∫ltiples queries iterativas o una query SQL muy compleja escrita por un experto."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JNGUl5eT0cx6"
      },
      "outputs": [],
      "source": [
        "query6 = \"En Europa, ¬øcu√°les son los 5 modelos m√°s vendidos de veh√≠culos el√©ctricos en el segmento Premium?\"\n",
        "\n",
        "print(f\"PREGUNTA: {query6}\\n\")\n",
        "print(\"=\"*80)\n",
        "response6 = agent_executor.invoke({\"input\": query6})\n",
        "print(\"=\"*80)\n",
        "print(f\"\\nüìä RESPUESTA FINAL:\\n{response6['output']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QKISAzf70cx6"
      },
      "source": [
        "### Pregunta 7: Uso de M√©tricas Derivadas - An√°lisis de Valor\n",
        "\n",
        "Esta pregunta usa la m√©trica `price_per_km` que calculamos en el feature engineering. Demuestra c√≥mo features num√©ricas permiten an√°lisis sofisticados de valor relativo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0kagCtw-0cx6"
      },
      "outputs": [],
      "source": [
        "query7 = \"¬øCu√°les son los modelos con mejor relaci√≥n precio-kilometraje (price_per_km m√°s bajo) en el segmento Luxury?\"\n",
        "\n",
        "print(f\"PREGUNTA: {query7}\\n\")\n",
        "print(\"=\"*80)\n",
        "response7 = agent_executor.invoke({\"input\": query7})\n",
        "print(\"=\"*80)\n",
        "print(f\"\\nüìä RESPUESTA FINAL:\\n{response7['output']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jyLfsd9j0cx6"
      },
      "source": [
        "### Pregunta 8: Uso de la Vista sales_summary\n",
        "\n",
        "Esta pregunta aprovecha la vista `sales_summary` que pre-calcula agregaciones. El agente puede consultar esta vista directamente en lugar de tener que construir agregaciones complejas desde la tabla base."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YwD5ZmT20cx6"
      },
      "outputs": [],
      "source": [
        "query8 = \"Usando la vista sales_summary, ¬øcu√°l fue el modelo con mayor volumen total de ventas en 2023?\"\n",
        "\n",
        "print(f\"PREGUNTA: {query8}\\n\")\n",
        "print(\"=\"*80)\n",
        "response8 = agent_executor.invoke({\"input\": query8})\n",
        "print(\"=\"*80)\n",
        "print(f\"\\nüìä RESPUESTA FINAL:\\n{response8['output']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9MumxRu0cx6"
      },
      "source": [
        "## 8. An√°lisis Reflexivo: Lecciones de Dise√±o para Sistemas de IA\n",
        "\n",
        "Ahora que hemos visto el agente en acci√≥n respondiendo diversas preguntas de negocio, es momento de reflexionar cr√≠ticamente sobre qu√© aspectos de nuestro dise√±o funcionaron bien y d√≥nde hay oportunidades de mejora. Esta metacognici√≥n es lo que distingue entre simplemente \"hacer que funcione\" y desarrollar intuici√≥n profunda sobre dise√±o de sistemas de IA.\n",
        "\n",
        "### Decisiones de Dise√±o que Amplificaron las Capacidades del Agente\n",
        "\n",
        "**Feature engineering expl√≠cito versus c√°lculos din√°micos:** Al pre-calcular features como `price_segment`, `product_line` y `vehicle_age`, permitimos que el agente genere queries simples y legibles. Sin estas features, el agente tendr√≠a que generar expresiones CASE complejas o aritm√©tica en cada query, lo cual es propenso a errores y m√°s dif√≠cil de optimizar para el motor de base de datos.\n",
        "\n",
        "**Normalizaci√≥n de nombres a snake_case:** Esta decisi√≥n aparentemente cosm√©tica tiene impacto real. Los nombres consistentes y sin case sensitivity reducen errores de sintaxis en el SQL generado. El agente no tiene que recordar si una columna es `Fuel_Type` o `fuel_type` o `fuelType`; todas siguen la misma convenci√≥n.\n",
        "\n",
        "**Vista sales_summary como abstracci√≥n:** Esta vista pre-calcula agregaciones comunes, transformando queries potencialmente complejas en simples SELECTs. Para el LLM, es m√°s f√°cil razonar sobre \"consulta la vista sales_summary\" que construir GROUP BYs anidados con m√∫ltiples agregaciones.\n",
        "\n",
        "**M√©tricas de valor relativo:** Columnas como `price_per_km` y `annual_depreciation` permiten comparaciones sofisticadas usando operadores SQL est√°ndar. Sin estas m√©tricas, preguntas sobre \"mejor valor\" o \"depreciaci√≥n r√°pida\" ser√≠an ambiguas o imposibles de responder con SQL puro.\n",
        "\n",
        "### Limitaciones y Oportunidades de Mejora\n",
        "\n",
        "**Ausencia de √≠ndices optimizados:** Para un dataset de 50,000+ registros, columnas frecuentemente filtradas como `region`, `year`, `model` y `price_segment` deber√≠an tener √≠ndices. Sin √≠ndices, queries con filtros complejos pueden ser lentas. SQLite crea algunos √≠ndices autom√°ticamente, pero no de forma √≥ptima.\n",
        "\n",
        "**Falta de metadata temporal granular:** El dataset contiene a√±os pero no fechas espec√≠ficas de venta. Esto limita an√°lisis de estacionalidad o tendencias mensuales. En un sistema de producci√≥n, tendr√≠amos timestamps completos.\n",
        "\n",
        "**Jerarqu√≠a de regiones no desarrollada:** Actualmente `region` es un string plano. En producci√≥n, tendr√≠amos una jerarqu√≠a (regi√≥n -> pa√≠s -> continente) que permitir√≠a agregaciones multi-nivel como \"analiza Europa como conjunto\" o \"compara rendimiento de pa√≠ses dentro de Asia\".\n",
        "\n",
        "**Sin modelado de clientes o dealers:** Este dataset representa transacciones an√≥nimas. Un sistema real tendr√≠a informaci√≥n sobre qui√©n compr√≥ (segmento de cliente) y d√≥nde (dealer espec√≠fico), permitiendo an√°lisis mucho m√°s ricos sobre comportamiento de compra y rendimiento de canales.\n",
        "\n",
        "### Limitaciones Fundamentales de Agentes SQL\n",
        "\n",
        "Incluso con el mejor dise√±o de base de datos posible, hay ciertos tipos de preguntas que los agentes SQL no pueden responder bien:\n",
        "\n",
        "**An√°lisis causal:** SQL puede decir \"qu√© pas√≥\" pero no \"por qu√© pas√≥\". Preguntas como \"¬øpor qu√© cayeron las ventas de sedanes en 2022?\" requieren razonamiento causal que va m√°s all√° de correlaciones estad√≠sticas que SQL puede calcular.\n",
        "\n",
        "**Forecasting:** Preguntas sobre el futuro (\"¬øcu√°les ser√°n las ventas de veh√≠culos el√©ctricos en 2025?\") requieren modelos predictivos que no son parte de SQL est√°ndar. Necesitar√≠as integrar con librer√≠as de machine learning.\n",
        "\n",
        "**An√°lisis de texto no estructurado:** Si tuvi√©ramos campos de texto libre como \"comentarios de clientes\" o \"notas de ventas\", SQL no puede hacer an√°lisis sem√°ntico profundo. Para eso necesitar√≠as t√©cnicas de NLP o embeddings vectoriales.\n",
        "\n",
        "**Comparaciones cross-dataset:** Si quisieras comparar ventas de BMW con datos de competidores que viven en otra base de datos o formato, el agente SQL tendr√≠a dificultades. Necesitar√≠as un orquestador de nivel superior.\n",
        "\n",
        "Entender estas limitaciones es tan importante como entender las capacidades. El dise√±o efectivo de sistemas de IA requiere saber cu√°ndo SQL es la herramienta correcta y cu√°ndo necesitas aproximaciones complementarias."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ohyJfDF00cx6"
      },
      "source": [
        "## 9. Conclusiones y Extensiones Avanzadas\n",
        "\n",
        "Has completado un ejercicio completo que simula un proyecto real de ingenier√≠a de IA aplicada a inteligencia de negocio. Transformaste datos crudos de ventas de veh√≠culos en un sistema conversacional que permite a stakeholders no t√©cnicos obtener insights sofisticados mediante preguntas en lenguaje natural. Este tipo de sistema es exactamente lo que empresas de todos los tama√±os necesitan para democratizar el acceso a datos y acelerar la toma de decisiones informadas.\n",
        "\n",
        "### Competencias Desarrolladas\n",
        "\n",
        "Has dominado el pipeline completo de preprocesamiento de datos orientado a IA, desde identificar oportunidades de feature engineering hasta implementar transformaciones que amplifican capacidades de razonamiento. Has aprendido a dise√±ar esquemas relacionales con empat√≠a hacia agentes LLM, considerando expl√≠citamente qu√© queries ser√°n comunes y c√≥mo facilitarlas mediante estructuras apropiadas. Has configurado y probado un agente SQL con LangChain, entendiendo tanto sus capacidades como sus limitaciones. Y has desarrollado intuici√≥n sobre el balance entre normalizaci√≥n, desnormalizaci√≥n y agregaci√≥n pre-calculada.\n",
        "\n",
        "### Extensiones Avanzadas para Profundizar\n",
        "\n",
        "Si quieres llevar este proyecto m√°s all√° como ejercicio de aprendizaje o como base para un proyecto profesional, considera estas direcciones:\n",
        "\n",
        "**Integraci√≥n con embeddings vectoriales para b√∫squeda h√≠brida:** Agrega una columna con embeddings de descripciones de modelos (generados con text-embedding-3-small de OpenAI). Esto permitir√≠a queries sem√°nticas como \"encuentra modelos similares al X5 en caracter√≠sticas y posicionamiento\" que van m√°s all√° de lo que SQL estructural puede hacer.\n",
        "\n",
        "**Dashboard interactivo con Streamlit:** Conecta la base de datos a un dashboard web usando Streamlit o Plotly Dash. El agente SQL podr√≠a alimentar visualizaciones din√°micas que se actualizan bas√°ndose en preguntas del usuario, combinando la potencia de SQL con la claridad de gr√°ficos.\n",
        "\n",
        "**Sistema de alertas autom√°ticas:** Implementa queries programadas que detecten anomal√≠as (por ejemplo, \"ventas de un modelo cayeron m√°s de 20% mes a mes\") y generen alertas autom√°ticas. El agente podr√≠a incluso generar explicaciones textuales de qu√© cambi√≥.\n",
        "\n",
        "**Modelo de predicci√≥n de precios:** Entrena un modelo de machine learning (Random Forest o XGBoost) para predecir precio de veh√≠culos bas√°ndose en caracter√≠sticas. Integra este modelo con el agente SQL para responder preguntas como \"¬øqu√© precio deber√≠a tener un X3 del 2023 con 50,000 km?\"\n",
        "\n",
        "**An√°lisis competitivo con m√∫ltiples marcas:** Extiende el dataset para incluir ventas de Mercedes, Audi y otros competidores. Modifica el esquema para soportar comparaciones cross-brand y an√°lisis de market share.\n",
        "\n",
        "**Pipeline de actualizaci√≥n automatizada:** Implementa un sistema que ingiere nuevos datos de ventas peri√≥dicamente, los procesa autom√°ticamente a trav√©s de tu pipeline de feature engineering, y actualiza la base de datos sin intervenci√≥n manual.\n",
        "\n",
        "**Sistema de permisos y seguridad:** En producci√≥n, diferentes usuarios deber√≠an tener acceso a diferentes niveles de detalle. Implementa Row-Level Security (RLS) para filtrar autom√°ticamente datos seg√∫n el rol del usuario.\n",
        "\n",
        "### Reflexi√≥n Final: Dise√±o Centrado en IA como Competencia Emergente\n",
        "\n",
        "Lo que has aprendido aqu√≠ trasciende esta implementaci√≥n espec√≠fica. Has desarrollado una forma de pensar sobre estructuraci√≥n de datos que considera expl√≠citamente las capacidades y limitaciones de sistemas de IA. Este \"dise√±o centrado en IA\" es una competencia emergente cada vez m√°s valiosa en la industria.\n",
        "\n",
        "No basta con organizar datos de forma l√≥gicamente correcta seg√∫n principios tradicionales de normalizaci√≥n de bases de datos. Debemos dise√±ar infraestructuras de datos pensando en c√≥mo ser√°n consumidas por agentes de IA, qu√© abstracciones facilitan su razonamiento, qu√© features ampl√≠fican sus capacidades, y qu√© estructuras minimizan la complejidad de las tareas que deben realizar.\n",
        "\n",
        "A medida que los sistemas de IA se vuelven m√°s capaces y omnipresentes, esta habilidad de dise√±ar datos \"AI-ready\" se convertir√° en una ventaja competitiva fundamental. Has dado un paso s√≥lido en esa direcci√≥n.\n",
        "\n",
        "---\n",
        "\n",
        "**Fin del Ejercicio Pr√°ctico - Pipeline de Datos BMW con Agente SQL**"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}